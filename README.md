# Scalable 3D Captioning with Pretrained Models

This is the code for our recent arXiv release: 

[Scalable 3D Captioning with Pretrained Models]()

[Chris Rockwell*](https://crockwell.github.io), [Tiange Luo*](https://tiangeluo.github.io/), [Honglak Lee†](https://web.eecs.umich.edu/~honglak/), [Justin Johnson†](https://web.eecs.umich.edu/~justincj)

*Equal contribution    †Equal Advising

Data download available at [Hugging Face]()

**Note** This repo is still preliminary. Full code is coming soon.

### To Do
  - [ ] Captioning Pipeline.
  - [ ] Captioning experiments.
  - [ ] Text-to-3D experiments.

### Citation
If you find this code useful, please consider citing:
```
    @article{Rockwell2023,
      author = {Chris Rockwell and Tiange Luo and Honglak Lee and Justin Johnson},
      title = {Scalable 3D Captioning with Pretrained Models},
      journal = {arXiv},
      year = 2023
    }
```

### Acknowledgments
This work is supported by two grants from LG AI Research and Grant #1453651 from NSF.
Thanks to <a href="https://mbanani.github.io/">Mohamed El Banani</a>, <a href="http://kdexd.xyz/">Karan Desai</a>, <a href="https://nileshkulkarni.github.io/">Ang Cao</a> and <a href="https://jinlinyi.github.io/">Linyi Jin</a> for their many helpful suggestions. Thanks <a href="https://mattdeitke.com/">Matt Deitke</a> for helping with Objaverse-related questions. 
